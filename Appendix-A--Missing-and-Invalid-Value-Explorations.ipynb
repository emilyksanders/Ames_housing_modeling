{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eddec03-7f22-43b2-ad2d-ebefd157862d",
   "metadata": {},
   "source": [
    "# **Real Estate: It's Ame-azing!**\n",
    "### *A report on predicting the sales price of houses in Ames, Iowa.*\n",
    "| | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |\n",
    "|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|\n",
    "|Emily K. Sanders| | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |Project 2: Ames Housing Prices|\n",
    "|DSB-318| | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |April 19, 2024|\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0499630-f6f5-4e5f-88b4-1ba12e3507af",
   "metadata": {},
   "source": [
    "### **Appendix B:** Missing and invalid value explorations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb8f636-9c0d-42df-8794-ed3316306db2",
   "metadata": {},
   "source": [
    "As described in the main notebook, I conducted thorough investigations into all missing and suspicious values in the dataset prior to partitioning it for training and testing, so as to maximize my familiarity with the types of values that are likely to be problems in future data.  This notebook details those investigations, and how I resolved each issue.  Although I fixed several individual values here, all of my actions were afterwards compiled into reproducible rules that can be applied to novel data without any of the hands-on work contained here.\n",
    "\n",
    "After importing the relevant modules, I generated several summary statistics and descriptions, and reviewed them for signs missing data, inappropriate data types, or signs of incorrect data.  Once those preliminary checks were complete, I began to dig more deeply into particular columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce750c0-1d1c-4874-9efa-669747298613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5036b260-c276-4521-94c6-4c9736ee9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "housing = pd.read_csv('./datasets/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc81547-4c80-4081-8cfd-929116ebe007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check it out\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70e5e84-46f8-4599-8ab5-9647e635d256",
   "metadata": {},
   "source": [
    "None the data types were unreasonable, nor did they suggest any \"messy\" values \"contaminating\" entire columns.  As I expected, some of the columns were formatted as objects (strings) and would have to be converted to numeric types to be included in the model, and some columns that might be best used as categorical were formatted as integers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bb088d-47e0-44e8-9eb6-f227f425dbc8",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9292d3b6-eba0-4df2-b740-dc0d7e7969ae",
   "metadata": {},
   "source": [
    "Because of the size of this dataset, I opted to create a dataframe containing the information on null values, rather than just generating this report in output.  Furthermore, to make it easier to see all 81 features and make notes on them, I saved this dataframe as a csv, and opened it in Excel to make notes in the margins.  A \"clean copy\" of the csv, as generated in the cell below, as well as my annotated copy, are included in the supplementary materials.  Please note that the annotated copy was only used for puzzling out the missing values; readers who cannot decipher my shorthand and sentence fragments will not be missing out on any important information.  Any reader who wishes to see the orignal output can do so by uncommenting the code snippet below, but for the reader's ease, a table of missing values is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89062a12-b457-4a2a-8efb-0848bf466afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a report of NAs and export it to CSV\n",
    "housing_nas = pd.DataFrame(housing.isna().sum())\n",
    "housing_nas.columns = ['NAs_count']\n",
    "housing_nas = housing_nas.sort_values(by = 'NAs_count', ascending = False)\n",
    "housing_nas.to_csv('./output/nas_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b64c4-0125-4025-8b67-ecb209442f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this code to see the dataframe within the report.\n",
    "#housing_nas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad4bf6af-3baf-40bc-939e-6c0a8e4012e5",
   "metadata": {},
   "source": [
    "|      Feature      |Null Count|    Feature    |Null Count|    Feature   |Null Count|\n",
    "|----------------------|----|----------------------|----|----------------------|----|\n",
    "|basemt_condition      |  55|garage_condition      | 114|masonry_type          |1240|\n",
    "|basemt_quality        |  55|garage_quality        | 114|masonry_area          |  22|\n",
    "|basemt_exposure       |  58|garage_type           | 113|pool_quality          |2042|\n",
    "|basemt_fin_1_qual     |  55|garage_year_built     | 114|fireplace_quality     |1000|\n",
    "|basemt_fin_2_qual     |  56|garage_finish         | 114|misc_feature          |1986|\n",
    "|basemt_fin_1_sf       |   1|garage_area           |   1|fence                 |1651|\n",
    "|basemt_fin_2_sf       |   1|garage_cars           |   1|alley                 |1911|\n",
    "|basemt_unf_sf         |   1|basemt_half_bath      |   2|lot_frontage          | 330|\n",
    "|basemt_total_sf       |   1|basemt_full_bath      |   2|**All Other Features**|   0|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887c77a-7884-4d0f-97e3-8de859aacf4f",
   "metadata": {},
   "source": [
    "Because the [received data dictionary](https://www.kaggle.com/competitions/318-ames-competition/data) says that NA was used to indicate houses that simply did not have a given element, I deemed it likely that any rows for which *all* of the basement-related columns were NA (or 0, where applicable) represented houses that simply did not have basements.  If the hypothesis that most of these NAs are tied to such houses were correct, then they would all be contained within the subset of the dataframe defined by isolating the basement-related feature with the greatest number of NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8564d44-d8fc-4600-90ee-63cf9c1e6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bsmt Exposure has the most NAs of the Bsmt categories\n",
    "basements = housing[housing['basemt_exposure'].isnull()]\n",
    "basements.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf99d8-c54c-4fc1-885c-1f65072e3755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print how many NAs of each of these columns are contained within the subset, out of total NAs for the column\n",
    "print(f\"Nulls contained within the rows where Exposure is null ({basements['basemt_exposure'].isnull().sum()}/58)\")\n",
    "print(f\"1. Condition: {basements['basemt_cond'].isnull().sum()}/55\")\n",
    "print(f\"2. Quality: {basements['basemt_qual'].isnull().sum()}/55\")\n",
    "print(f\"3. Finished 1 Type: {basements['basemt_fin_1_qual'].isnull().sum()}/55\")\n",
    "print(f\"4. Finished 2 Type: {basements['basemt_fin_2_qual'].isnull().sum()}/56\")\n",
    "print(f\"5. Half baths: {basements['basemt_half_bath'].isnull().sum()}/2\")\n",
    "print(f\"6. Full baths: {basements['basemt_full_bath'].isnull().sum()}/2\")\n",
    "print(f\"7. Unfinished Sqft: {basements['basemt_unf_sf'].isnull().sum()}/1\")\n",
    "print(f\"8. Finished 1 Sqft: {basements['basemt_fin_1_sf'].isnull().sum()}/1\")\n",
    "print(f\"9. Finished 2 Sqft: {basements['basemt_fin_2_sf'].isnull().sum()}/1\")\n",
    "print(f\"10. Total Sqft: {basements['basemt_total_sf'].isnull().sum()}/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba31e68-4019-492d-b3e7-1d47188ed0d9",
   "metadata": {},
   "source": [
    "All but one of these NAs were contained within the subsetted dataframe.  Notably, the descriptive columns very consistently had 55 NAs, and the quantitative columns - for which 0 is a valid, non-NA entry - had much fewer.  Below I have listed the number of 0s in these quantitative columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37295513-1d14-4408-822d-757d2234a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Furthermore, the number of 0s in these columns are:\")\n",
    "print(f\"5. Half baths: {len(basements[basements['basemt_half_bath']==0])}\")\n",
    "print(f\"6. Full baths: {len(basements[basements['basemt_full_bath']==0])}\")\n",
    "print(f\"7. Unfinished Sqft: {len(basements[basements['basemt_unf_sf']==0])}\")\n",
    "print(f\"8. Finished 1 Sqft: {len(basements[basements['basemt_fin_1_sf']==0])}\")\n",
    "print(f\"9. Finished 2 Sqft: {len(basements[basements['basemt_fin_2_sf']==0])}\")\n",
    "print(f\"10. Total Sqft: {len(basements[basements['basemt_total_sf']==0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1b0ba-4a35-4d80-bcba-1cb23773596a",
   "metadata": {},
   "source": [
    "For every one of these features, the sum of the NAs and the 0s was equal to or greater than 55.  It is completely plausible that someone could have a basement without any bathrooms or finished space in it - indeed, I was surprised those columns did not have *more* 0s - so the columns with more than 55 NAs or 0s were of no concern.  The fact that no columns had *fewer* than 55 NAs or 0s - i.e., the columns were consistent \"no\"s all across the way - indicated that these \"missing\" values were only missing a readable format; they were not missing *information*.  They showed that 55 of the houses in the dataset did not have basements.\n",
    "\n",
    "The only remaining mysteries in this section were the single NA in *basemt_finished_type_2* and the 3 NAs in *basemt_exposure* that exist outside of these core 55.  Because this was at most 4 rows, I subsetted down to them and inspected them visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60607a30-1ea5-4c58-9b9b-eacbb7c6dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude those 55 houses with no basements\n",
    "basements2 = housing[housing['basemt_fin_1_qual'].notnull()]\n",
    "# Isolate the remaining null values\n",
    "basements2 = basements2[(basements2['basemt_fin_2_qual'].isnull()) | (basements2['basemt_exposure'].isnull())]\n",
    "basements2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e6766-8066-4151-8cda-7c807566372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For context\n",
    "print(housing['basemt_exposure'].value_counts(dropna = False))\n",
    "print(housing['basemt_fin_2_qual'].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca72596b-7a5a-4fea-b053-5464d8c1ff09",
   "metadata": {},
   "source": [
    "All 4 of these rows had populated, plausible values throughout the other basement-related columns, and did not present any obvious data integrity concerns elsewhere.  I concluded that these NAs were errors.\n",
    "\n",
    "Because so many houses with basements had a \"No\" in the *bsmt_exposure* column - which makes sense, given that basements are usually underground - I was willing to assume that that was the intended value for the 3 NAs in rows that otherwise clearly indicate the presence of a basement, and changed them to \"No.\"  The 1 remaining NA in the *basemt_finished_type_2* was harder to understand.  With no real clues to go on, I changed this to \"not-present\" along with all the other NAs in this column, even though the row indicated that the house did have a basement.  Although that imputation is technically incorrect, it was likely the best solution to the problem.  Whatever the true information is, it was unavailable, and thus of no more use in the model than if it did not exist at all.  That house got \"credit\" in the model for having a basement via its other, correctly populated features, and did not receive \"unearned credit\" through incorrect imputation here.\n",
    "\n",
    "For the quantitative columns, I replaced the NAs with 0s.  For the qualitative columns, I replaced the NAs with \"not-present\" to make later dummy coding easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed9131b-0830-4cc3-8e06-9eece62ede46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing those 3 exposure NAs with other populated features to \"No\"\n",
    "housing.loc[((housing['basemt_exposure'].isna()) & (housing['basemt_cond'].notna())), 'basemt_exposure'] = 'No'\n",
    "print('There were previously 1339 \"No\"s.')\n",
    "print(housing['basemt_exposure'].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e077841-8995-46d9-89f0-4865c6667732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing rest of the NAs\n",
    "housing['basemt_exposure'] = housing['basemt_exposure'].fillna('not-present')\n",
    "housing['basemt_cond'] = housing['basemt_cond'].fillna('not-present')\n",
    "housing['basemt_qual'] = housing['basemt_qual'].fillna('not-present')\n",
    "housing['basemt_fin_1_qual'] = housing['basemt_fin_1_qual'].fillna('not-present')\n",
    "housing['basemt_fin_2_qual'] = housing['basemt_fin_2_qual'].fillna('not-present')\n",
    "housing['basemt_half_bath'] = housing['basemt_half_bath'].fillna(0)\n",
    "housing['basemt_full_bath'] = housing['basemt_full_bath'].fillna(0)\n",
    "housing['basemt_unf_sf'] = housing['basemt_unf_sf'].fillna(0)\n",
    "housing['basemt_fin_1_sf'] = housing['basemt_fin_1_sf'].fillna(0)\n",
    "housing['basemt_fin_2_sf'] = housing['basemt_fin_2_sf'].fillna(0)\n",
    "housing['basemt_total_sf'] = housing['basemt_total_sf'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9395f2ad-0665-44a4-8d1f-3fe1dfad19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechecking the null counts\n",
    "print(f\"0. Exposure: {housing['basemt_exposure'].isnull().sum()}/58)\")\n",
    "print(f\"1. Condition: {housing['basemt_cond'].isnull().sum()}/55\")\n",
    "print(f\"2. Quality: {housing['basemt_qual'].isnull().sum()}/55\")\n",
    "print(f\"3. Finished 1 Type: {housing['basemt_fin_1_qual'].isnull().sum()}/55\")\n",
    "print(f\"4. Finished 2 Type: {housing['basemt_fin_2_qual'].isnull().sum()}/56\")\n",
    "print(f\"5. Half baths: {housing['basemt_half_bath'].isnull().sum()}/2\")\n",
    "print(f\"6. Full baths: {housing['basemt_full_bath'].isnull().sum()}/2\")\n",
    "print(f\"7. Unfinished Sqft: {housing['basemt_unf_sf'].isnull().sum()}/1\")\n",
    "print(f\"8. Finished 1 Sqft: {housing['basemt_fin_1_sf'].isnull().sum()}/1\")\n",
    "print(f\"9. Finished 2 Sqft: {housing['basemt_fin_2_sf'].isnull().sum()}/1\")\n",
    "print(f\"10. Total Sqft: {housing['basemt_total_sf'].isnull().sum()}/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a8016-a622-40bb-a8f4-f8beff27e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechecking the 0 counts\n",
    "print(\"Furthermore, the number of 0s in these columns are:\")\n",
    "print(f\"5. Half baths: {len(housing[housing['basemt_half_bath']==0])}, from 1923\")\n",
    "print(f\"6. Full baths: {len(housing[housing['basemt_full_bath']==0])}, from 1200\")\n",
    "print(f\"7. Unfinished Sqft: {len(housing[housing['basemt_unf_sf']==0])}, from 165\")\n",
    "print(f\"8. Finished 1 Sqft: {len(housing[housing['basemt_fin_1_sf']==0])}, from 657\")\n",
    "print(f\"9. Finished 2 Sqft: {len(housing[housing['basemt_fin_2_sf']==0])}, from 1803\")\n",
    "print(f\"10. Total Sqft: {len(housing[housing['basemt_total_sf']==0])}, from 54\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c5d8e1-3e69-4b6c-9dee-0737196576f5",
   "metadata": {},
   "source": [
    "Displayed below is a very similar analysis for the garage-related features, which were also noted in the received data dictionary to use NA as a marker for not having a garage.  For brevity, because this analysis is so similar to the basements section, each step is accompanied by much less, if any, explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce7cdc-7c2c-418e-b6eb-dc9acb533a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garage Condition has the maximum number of NAs in the garage columns (not exclusively)\n",
    "garages = housing[housing['garage_cond'].isnull()]\n",
    "garages.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6955a05-8129-4d45-923d-859d66c87a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print how many NAs of each of these columns are contained within the subset, out of total NAs for the column\n",
    "print(f\"Nulls contained within the rows where Condition is null ({garages['garage_cond'].isnull().sum()}/114)\")\n",
    "print(f\"1. Quality: {garages['garage_qual'].isnull().sum()}/114\")\n",
    "print(f\"2. Type: {garages['garage_type'].isnull().sum()}/113\")\n",
    "print(f\"3. Year Built: {garages['garage_yr_blt'].isnull().sum()}/114\")\n",
    "print(f\"4. Finish: {garages['garage_finish'].isnull().sum()}/114\")\n",
    "print(f\"5. Area: {garages['garage_area'].isnull().sum()}/1\")\n",
    "print(f\"6. Cars: {garages['garage_cars'].isnull().sum()}/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686ee0cb-69e9-4504-937f-78f7e7ba7e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Furthermore, the number of 0s in these columns are:\")\n",
    "print(f\"5. Area {len(garages[garages['garage_area']==0])}\")\n",
    "print(f\"6. Cars {len(garages[garages['garage_cars']==0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab192c-7977-48be-8610-e7ff41db305c",
   "metadata": {},
   "source": [
    "Every single one of these NAs was contained within the same subset of rows, and displayed the same pattern as the basements: the descriptive features had high, consistent NA counts, and the quatitative features, for which 0 is a valid entry, had many fewer NAs.  Indeed, these features had exactly enough 0s to match the NAs in the descriptive features.  Unlike *basemt_half_bath*, for example, which may be 0 even in a house with a basement, it is not possible for a garage to exist but have no area, so if my interpretation of these NAs and 0s was correct, these columns should not have had 0s in any rows that had other populated garage features.  (Although a homeowner could conceivably use the word \"garage\" to refer to a space not large enough for even a single car, it seems likely that such a structure would be represented in the dataset as *misc_feature - shed*, rather than as a garage.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d10d05-e174-49f3-8af0-f107dd91136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Furthermore, the TOTAL number of 0s in these columns are:\")\n",
    "print(f\"5. Area {len(housing[housing['garage_area']==0])}\")\n",
    "print(f\"6. Cars {len(housing[housing['garage_cars']==0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84611ac6-ed69-49a3-8e11-9cf0b08a1135",
   "metadata": {},
   "source": [
    "As predicted, these columns had no 0s except for the ones in the rows of interest.\n",
    "\n",
    "The final step before concluding that these houses simply do not have garages was to investigate why *garage_type* is populated in a row where none of the others were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88865d1b-32f9-4c4c-a2e3-0e5afe757b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row = garages[garages['garage_type'].notnull()]\n",
    "test_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212192fb-cae0-413d-a8c6-50b3db1185bd",
   "metadata": {},
   "source": [
    "This row did not show signs of overall corruption, which made the option of simply dropping it unappealing.  However, the *garage_type* column, which indicated a detached garage, stood in contrast to every other indicator, which pointed towards this house not having a garage at all.  There was risk of introducing error no matter what I did with this value.  \n",
    "\n",
    "To get a sense of how this incongruous value may have come to be, I dug deeper into the [provenance of the dataset](https://jse.amstat.org/v19n3/decock.pdf): the records system in the Ames City Assessor's Office (de Cock, 2011).  This narrowed the possibilities.  While volunteer respondents may misrepresent or omit data for any number of reasons, a government office tasked with assessing taxes on the populace is much less likely to engage in mischievous reporting or fatigue attrition.  Therefore, I concluded that this discrepancy was more likely to be a mistake than to be an incomplete but otherwise accurate report.  The fact that this was the same row where *garage_cars* and *garage_area* were marked NA, rather than 0 like in all other relevant rows, further supported my hypothesis that there was something wrong with it, rather than the idea that it was simply missing some information.  Therefore, I assumed that the house did not have a garage, this value was recorded erroneously, and thus, to remove it.  I did this by specifying the exact row for the data at hand, but wrote a cleaning code at the end of my investigations to generalize it to future data without the need for hands-on intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1279f-4460-41a3-9b29-9d6a4ad715b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing.loc[housing['pid']==910201180, 'garage_type'])\n",
    "housing.loc[housing['pid']==910201180, 'garage_type'] = np.nan\n",
    "print(housing.loc[housing['pid']==910201180, 'garage_type'])\n",
    "print(housing['garage_type'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5823e4-ffb6-48a4-81ee-b8e5eca463b5",
   "metadata": {},
   "source": [
    "With that, the mystery of the garage-related NAs was solved, and I corrected the values in the same way as with the basements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08640176-5346-4b28-9801-e755ef9c69a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing rest of the NAs\n",
    "housing['garage_cond'] = housing['garage_cond'].fillna('not-present')\n",
    "housing['garage_qual'] = housing['garage_qual'].fillna('not-present')\n",
    "housing['garage_type'] = housing['garage_type'].fillna('not-present')\n",
    "housing['garage_yr_blt'] = housing['garage_yr_blt'].fillna('not-present')\n",
    "housing['garage_finish'] = housing['garage_finish'].fillna('not-present')\n",
    "housing['garage_area'] = housing['garage_area'].fillna(0)\n",
    "housing['garage_cars'] = housing['garage_cars'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00176a1-5a2f-4543-be88-20c7a45c79c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechecking the NA counts\n",
    "print(f\"0. Condition: {housing['garage_cond'].isnull().sum()}/114\")\n",
    "print(f\"1. Quality: {housing['garage_qual'].isnull().sum()}/114\")\n",
    "print(f\"2. Type: {housing['garage_type'].isnull().sum()}/113\")\n",
    "print(f\"3. Year Built: {housing['garage_yr_blt'].isnull().sum()}/114\")\n",
    "print(f\"4. Finish: {housing['garage_finish'].isnull().sum()}/114\")\n",
    "print(f\"5. Area: {housing['garage_area'].isnull().sum()}/1\")\n",
    "print(f\"6. Cars: {housing['garage_cars'].isnull().sum()}/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a531d-624d-4d0c-ad15-821ada893530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechecking the 0s\n",
    "print(\"Furthermore, the number of 0s in these columns are:\")\n",
    "print(f\"5. Area {len(housing[housing['garage_area']==0])}, from 113\")\n",
    "print(f\"6. Cars {len(housing[housing['garage_cars']==0])}, from 113\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6999d069-2e8a-4723-985d-a4ccd6bee9ee",
   "metadata": {},
   "source": [
    "Those two investigations resolved the bulk of the NAs.  I used similar methods on the rest.  \n",
    "\n",
    "The columns *masonry_type* and *masonry_area* were the only two columns in the dataset that refered to masonry, and thus could only be cross-checked with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24638538-0622-4d20-bfe5-d2d8b1c02c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['masonry_type'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d7010-545e-444b-9335-6f9cd2f0cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset by the column with more NAs\n",
    "masonry = housing[housing['masonry_type'].isnull()]\n",
    "# See how many of the masonry_areas NAs overlap with the masonry_type NAs\n",
    "print(f\"Overlap: {masonry['masonry_area'].isnull().sum()}/22 total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320a8f84-a7f7-4b1b-b4c2-6076e2a037a1",
   "metadata": {},
   "source": [
    "Once again, there was a wide discrepancy between a descriptive and a quantitative feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c104dae7-15ab-4ea8-bfb1-e6ca7703494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Subset masonry_area 0s: {len(masonry[masonry['masonry_area']==0])}\")\n",
    "print(f\"1213+22=1235\")\n",
    "print(f\"Total masonry_area 0s: {len(housing[housing['masonry_area']==0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db931811-1061-462f-a8ce-a5194d6b4bb6",
   "metadata": {},
   "source": [
    "Combining the 0s and the NAs in the quantitative column once again produced a sum very close to the number of NAs in the descriptive column, but not exactly the same.  There were 5 rows within the subset (i.e.,  *masonry_type* is NA) that had non-zero values in *masonry_area*, and 3 additional rows outside of the subset (i.e., *masonry_type* is populated) that had 0s in *masonry_area*.  Logically, any row with an NA in *masonry_type* should have had a 0 in *masonry_area*, and vice versa.  If masonry veneer were not present on the house, it would not take up area, and if it took up area, it was present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a64d9-ff12-46e5-b7e5-6654afcf695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the subset in which all masonry_type = NA\n",
    "# Filter out the NAs in area\n",
    "have_area_no_type = masonry[masonry['masonry_area'].notnull()]\n",
    "# Filter out the 0s in area\n",
    "have_area_no_type = have_area_no_type[have_area_no_type['masonry_area']!= 0]\n",
    "# Review the rows that are populated in area but not in type\n",
    "have_area_no_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91a3752-be33-4aa0-ae7e-8dedda01649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the values?\n",
    "have_area_no_type['masonry_area'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce7377-a0a7-408f-8a55-81756a1695e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For context\n",
    "housing['masonry_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf98551-bec6-4161-ac99-9de0822ed7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more context\n",
    "#housing.loc[housing['Mas Vnr Area']>0, 'Mas Vnr Area'].sort_values().head(20)\n",
    "# Note: I commented this code out after using it because the output is long. Single digit areas are unusual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f09dc94-bd69-4774-a17b-54f308bc18f6",
   "metadata": {},
   "source": [
    "There were only 3 non-null values that *masonry_type* took in th dataset - brick face, brick common, or stone - and the received data dictionary listed only one more, cinder block.  This is a very short list of potential types of masonry.  A [cursory search](https://www.homequestionsanswered.com/what-is-masonry-veneer.htm) suggested that brick and stone do technically cover all the options, but there are [more subcategories](https://www.civilengineeringweb.com/2020/09/types-of-stone-masonry.html) than the ones that were given as options.  Given this fact, I found it plausible that some houses had a type of veneer that was not listed among the available choices (or, perhaps, that the assessor could not identify), and were thus erroneously coded as NA in the *masonry_type* column, despite actually having some masonry veneer.  \n",
    "\n",
    "The fact that the 3 smallest areas (1 square foot each) in the dataset fell within this subset of 5 rows further supported this explanation.  These houses may well have had a small, ornamental piece of masonry work that did not fall neatly into any of the options for *masonry_type*.  Working under this hypothesis, I left these values in and changed the corresponding NAs in *masonry_type* to \"other.\"  At the very least, the small number of affected values and their small *masonry_area*s limited the damage these values could cause in the model.\n",
    "\n",
    "As for the other two rows with a populated *masonry_area* but NA *masonry_type*, these were challenging decisions.  The values were large enough that, if erroneous and if *masonry_area* proved to be a useful predictor, they could introduce a great deal of error into the predictions.  Ultimately, I relied on the assumption that such specific values (288 and 344), with multiple digits and not ending in 0 or 5, were unlikely to be accidents, mischievous reports, or misplaced statistical artifacts.  Much like in the basement analysis, I put a great deal of faith into the provenance of this dataset, and based my decisions on the simplifying assumption that government files are more likely to be accurate and complete than other sources (i.e., volunteer survey data), and therefore erred on the side of preserving the data as it was received.  For these values too, I changed the corresponding NAs in *masonry_type* to \"other.\"\n",
    "\n",
    "Although I once again corrected these rows by name for convenience's sake, I accounted for this situation in the hands-off cleaning code for future data.  The fact that all of the rows with a populated area but an NA for type were resolved the same way made this considerably easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9570901d-93fa-4056-943d-bd3555a9bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a shortcut to these rows\n",
    "pids = (housing['pid']==533352075) | (housing['pid']==534129230) | (\n",
    "    housing['pid']==535106140) | (housing['PID']==902427140) | (housing['pid']==527166010)\n",
    "#change the value\n",
    "housing.loc[pids, 'masonry_type'] = 'other'\n",
    "#check\n",
    "housing.loc[pids, 'masonry_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9385d5c-9c4d-494f-834f-b23545808696",
   "metadata": {},
   "source": [
    "Next, I examined the 3 rows that had 0s in *masonry_area*, but values in *masonry_type*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62710a9f-a765-4074-b0c9-74a13ecd197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "masonry = housing[housing['masonry_area']==0]\n",
    "len(masonry) #1216\n",
    "masonry = masonry[masonry['masonry_type'].notnull()]\n",
    "len(masonry) #3\n",
    "masonry.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0525d7c4-d591-40a7-bfbf-e29b2dd4c6d6",
   "metadata": {},
   "source": [
    "The contrast between these two features was the only apparent problem with these rows, so I was disinclined to drop them.  Logically, there were two possible explanations for a row to list a type of masonry but no area: either the type was listed by mistake, or the masonwork was so small that it was rounded to 0.  In my opinion, either way, these houses would be better considered as having no masonry.  I cleared these entries in *masonry_type* and recoded them along with the other NAs.  This situation too was accounted for in the future-facing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cdbf65-f25a-4f06-aa74-b1caac1244f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a shortcut to these rows\n",
    "pids = (housing['pid']==528222090) | (housing['pid']==527252070) | (\n",
    "    housing['pid']==528435060)\n",
    "# Change the value\n",
    "housing.loc[pids, 'masonry_type'] = np.nan\n",
    "# Check\n",
    "housing.loc[pids, 'masonry_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3d0548-351a-4e88-86e3-5902f8f54ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode the NAs\n",
    "housing['masonry_type'] = housing['masonry_type'].fillna('not-present')\n",
    "housing['masonry_area'] = housing['masonry_area'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e464f00-b3ab-4667-996b-65b80f83c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recheck the values\n",
    "print(f\"Type: {housing['masonry_type'].isnull().sum()} NAs, from 1238\")\n",
    "print(housing['masonry_type'].value_counts())\n",
    "print(f\"Area: {len(housing[housing['masonry_area']==0])} 0s, from 1216\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508954b-93f6-4dc2-b186-ea6f6a16031b",
   "metadata": {},
   "source": [
    "As seen above, the NAs in *masonry_type* matched the 0s in *masonry_area* post-corrections.\n",
    "\n",
    "Of the remaining features with NAs, *pool_quality*, *fireplace_quality*, and *misc_feature* were the ones easiest to cross-check against other features: *pool_area*, *fireplaces* (the count), and *misc_value* (monetary value of miscellaneous elements in a house), respectively.  Once again, all of these features were listed in the received data dictionary as using NA to indicate houses that do not have the particular element, so I was not overly concerned about these NAs.  However, in the interest of caution and maximizing my knowledge with which to write the future-facing code, I conducted the investigation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc36727-3e3f-4306-8024-44e7fb63b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pools\n",
    "housing['pool_qc'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24730d09-20d3-425c-b7b7-50763e5e8747",
   "metadata": {},
   "source": [
    "The idea that only 9 of these houses in Ames, Iowa had pools struck me as extremely plausible.  Students at Iowa State University have [access to a pool for free](https://cyclonehealth.iastate.edu/recreation/membership), and would likely be loathe to take on the costs of owning a pool.  Non-students can also use the ISU pool for a fee, or any of [several municipal pools](https://www.cityofames.org/government/departments-divisions-i-z/parks-recreation/aquatics-pool-information-and-season-pass-fees).  As long as this value matched up with the values in *pool_area*, I saw no reason to be suspicious of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5137a4-ac48-494d-9450-7ac16b93f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset by the NAs\n",
    "pools = housing[housing['pool_qc'].isnull()]\n",
    "pools.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a97e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many total 0s are there?\n",
    "housing['pool_area'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ae2d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of those 0s overlap with NAs?\n",
    "pools['pool_area'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cbc449-9e25-4878-8e81-4d55d71a2dae",
   "metadata": {},
   "source": [
    "The pool-related values matched up perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa820bda-be0b-400b-aba4-dee6d16bc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fireplaces\n",
    "housing['fireplace_qu'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cead2e8-3720-4d1f-a31e-b92a02a32c10",
   "metadata": {},
   "source": [
    "Once again, these numbers seemed perfectly plausible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf3877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset by the NAs\n",
    "fireplaces = housing[housing['fireplace_qu'].isnull()]\n",
    "fireplaces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many total 0s are there?\n",
    "housing['fireplaces'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cb1433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of those 0s overlap with NAs?\n",
    "fireplaces['fireplaces'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c771113c-4800-4321-9622-f71116e2cf82",
   "metadata": {},
   "source": [
    "The fireplace-related values matched up perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc. Features\n",
    "housing['misc_feature'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac459cc-90cc-4c1c-8984-98f6096d6287",
   "metadata": {},
   "source": [
    "These numbers also seemed perfectly plausible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc2ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset by the NAs\n",
    "miscs = housing[housing['misc_feature'].isnull()]\n",
    "miscs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffd0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many total 0s are there?\n",
    "len(housing[housing['misc_val']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28350ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of those 0s overlap with NAs?\n",
    "len(miscs[miscs['misc_val']==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad365e7-5f97-4041-9726-8033bf7cb4e2",
   "metadata": {},
   "source": [
    "The miscellaneous-related values matched up perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d059a8d6-a506-42b8-8ab7-d77b2335bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode these NAs\n",
    "housing['pool_qc'] = housing['pool_qc'].fillna('not-present')\n",
    "housing['fireplace_qu'] = housing['fireplace_qu'].fillna('not-present')\n",
    "housing['misc_feature'] = housing['misc_feature'].fillna('not-present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recheck these rows\n",
    "print(f\" Pools: {housing['pool_qc'].isnull().sum()} NAs, from 2042\")\n",
    "print(f\"{len(housing[housing['pool_qc']=='not-present'])} recoded values\")\n",
    "print(f\" Fireplaces: {housing['fireplace_qu'].isnull().sum()} NAs, from 1000\")\n",
    "print(f\"{len(housing[housing['fireplace_qu']=='not-present'])} recoded values\")\n",
    "print(f\" Pool: {housing['misc_feature'].isnull().sum()} NAs, from 1986\")\n",
    "print(f\"{len(housing[housing['misc_feature']=='not-present'])} recoded values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c008bcb-a0b1-43da-9aa0-49b226f0200f",
   "metadata": {},
   "source": [
    "The features *fence* and *alley* were also listed in the received data dictionary as using NA to indicate houses that did not have these elements, and there were no obvious candidates to cross-check them with.  With no other option, I am assumed that these NAs were all being used correctly, and recoded them to make future dummy coding smoother.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532317f9-c2ea-45b8-b64a-d9412b54c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fences\n",
    "print(housing['fence'].value_counts(dropna = False))\n",
    "# Alleys\n",
    "housing['alley'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eb05a4-6f09-479f-a06c-abbd5d318ea4",
   "metadata": {},
   "source": [
    "Thankfully, these numbers seemed plausible.  There would not have been anything to do if they did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06b053-c703-4138-8562-7bfed2a18efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode the NAs\n",
    "housing['fence'] = housing['fence'].fillna('not-present')\n",
    "housing['alley'] = housing['alley'].fillna('not-present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cca317-0dd7-4ca5-9619-d4fc98d90b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recheck\n",
    "print(f\" Fences: {housing['fence'].isnull().sum()} NAs, from 1651\")\n",
    "print(f\"{len(housing[housing['fence']=='not-present'])} recoded values\")\n",
    "print(f\" Alleys: {housing['alley'].isnull().sum()} NAs, from 1911\")\n",
    "print(f\"{len(housing[housing['alley']=='not-present'])} recoded values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e33a9ee-9d71-4d98-bb61-0c1fe4e7d870",
   "metadata": {},
   "source": [
    "Finally, only *lot_frontage* remained.  This feature, unlike most of the others, did not list any purposeful use of NAs, despite having one of the highest numbers of them (*n*=330).  There were no NAs or 0s in *lot_area*, and how a lot could have no frontage (defined as \"[Linear feet of street connected to property](https://www.kaggle.com/competitions/318-ames-competition/data)\") defied my comprehension.  The only possibility I could come up with is that these lots had no frontage to a road because they were instead accessed by alleys.  Below, I checked this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c28018d-9c13-4ebd-ad69-35ca87d41abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that it's not a wider problem with lot dimensions\n",
    "print(f\"NAs in lot_area: {housing['lot_area'].isnull().sum()}\")\n",
    "print(f\"0s in lot_area: {len(housing[housing['lot_area']==0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd427dd-c746-4b59-a9fb-6e7f5bcaa13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset by non-NAs\n",
    "alleys = housing[housing['alley']!='not-present'] #houses must HAVE an alley to be accessed by alley\n",
    "alleys.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ea21a1-d53d-44e0-9c2d-a76aa0f2fadf",
   "metadata": {},
   "source": [
    "My hypothesis about alley access seemed dubious at best.  There were more than double the number of houses with an NA in *lot_frontage* than there were with alleys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57399f1-9a53-4412-9b90-aac58d2ca525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lot_frontage NAs and 0s\n",
    "print(f\"lot_frontage 0s: {len(housing[housing['lot_frontage']==0])}\")  #good\n",
    "print(f\"lot_frontage NAs overall: {housing['lot_frontage'].isnull().sum()}\")\n",
    "#overlap\n",
    "print(f\"lot_frontage NAs in subset: {alleys['lot_frontage'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7de9f9-58e8-457e-a0af-8a72b33c4bdb",
   "metadata": {},
   "source": [
    "At best, my hypothesis could explain 8 rows.  I inspected these rows in hopes of gaining further insight, but was not optimistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5819c188-d362-4cd0-824b-3f826061518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontage = alleys[alleys['lot_frontage'].isnull()]\n",
    "print(frontage.shape)\n",
    "frontage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f064ae1-0dc3-42e5-9b94-2b2706435170",
   "metadata": {},
   "source": [
    "None of these rows were remarkable in any way, forcing me to conclude that the NAs in *lot_frontage* were truly missing data.  There should have been a value there, but there is not.\n",
    "\n",
    "Although imputation always carries a risk of introducing error, dropping 330 out of 2051 rows (16%) would have been a dramatic loss, and leaving them as NA would have effectively dropped them from the model anyway - if the model could even be fit at all with them present.  I decided imputation was the only path forward for these values.  Because imputation often requires the use of statistics gathered from the dataset itself, I delayed this process until after partitioning the data for training and testing.  I did, however, explore some summary statistics for *lot_frontage* and related features to get an idea of what the best imputation strategy might be.  These are displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3db212-ac70-4557-ad73-71ce4d25deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine subset to be more useful\n",
    "frontage = housing[housing['lot_frontage'].isnull()] \n",
    "print(frontage.shape)\n",
    "housing['lot_frontage'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9a84b5-186f-4c25-810c-99b0958ff828",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "plt.hist(housing['lot_frontage'], color = 'purple', bins = 30);\n",
    "plt.title('Distribution of Extant Lot Frontage Values', size = 30)\n",
    "plt.xlabel('Lot Frontage Values', size = 24)\n",
    "plt.xticks(size = 16)\n",
    "plt.axline(xy1=(housing['lot_frontage'].median(), 0),\n",
    "           xy2=(housing['lot_frontage'].median(), 2), color = 'yellow')\n",
    "plt.ylabel('Frequency', size = 24)\n",
    "plt.yticks(size = 16);\n",
    "plt.tight_layout()\n",
    "plt.savefig(fname = 'lot-frontage-histogram.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57311a2d-a6f4-46b6-ade1-9bcc9b817107",
   "metadata": {},
   "source": [
    "The descriptive statistics for *lot_frontage* indicated that the mean and median were very close together, which can be indicative of a normal distribution.  I plotted the distribution in hopes of confirming this, but instead discovered a severe right skew.  The distribution up to about a value of 100 was close enough to normal to be sufficient in most cases, but beyond that, a long tail of values extends past 300.  Of course, a normal distribution is nott necessary for imputation, but it would have been a positive sign that a measure of central tendency could be safely imputed without causing too many problems.\n",
    "\n",
    "Because of the extreme skew, I became inclined to impute the mode (which also happened to be the median) rather the mean.  Before doing that though, I wanted to make sure it would not create absurdities in the context of other measurements in these rows.  In particular, I wanted to make sure that setting all of these *lot_frontage* values to about 68 feet would not make their *lot_area* values mathematically impossible. To do this, I needed some summary statistics about *lot_area* within the subset of rows for which *lot_frontage* is NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa5e17-9ab6-44ed-acca-a95df2560e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontage['lot_area'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb65f858-718b-4e6f-b4c6-925dfb691e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "1533/68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944e61a1-5ea9-4958-848a-208a31bc2384",
   "metadata": {},
   "source": [
    "The minimum lot area represented in these rows was 1533 square feet.  If that were a rectangular lot, with one side adjacent to a road, with 68 feet of frontage, the other side would have had to be 22.54 feet.  That would be a tight fit for sure, but not impossible.  With a positive, double-digit number possible, I decided to impute these values when the time came."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c6a6d-fe79-4926-b1be-757dbd62c5e3",
   "metadata": {},
   "source": [
    "The last thing to investigate were a handful of columns that had 0s listed as their minimum values, despite that not making sense.  As discussed previously, the fact that this dataset came from a government record led me to assume that it was compiled with more care and diligence than average survey data, and therefore err on the side of leaving it as it was wherever possible.  Therefore, despite it being very weird, I decided to assume that the 0s in the columns for above-ground kitchens (*n*=2) and bedrooms (*n*=5) were correct.  A kitchen or a bedroom would have been a very big thing for an assessor to miss, and these values were populated with 0s, not NAs - implying that someone typed that in on purpose.  Additionally, the received data dictionary specified that the bedroom column referred to *above-ground* bedrooms, and the original column name for kitchens, *\"Kitchen AbvGr,\"* implied the same.  No information was offered about any potential below-ground kitchens or bedrooms, meaning that 0s in these columns did not necessarily imply that a house had no kitchens or bedrooms at all.  Further support for this interpretation came from checking the basement exposure ratings of these houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c163fa-934a-45fc-b9ab-263f688aecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate houses with no above-ground kitchens\n",
    "no_kitch = housing[housing['kitchen_abvgr']==0]\n",
    "# Look at the exposures of their basements\n",
    "no_kitch['basemt_exposure'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f058c278-1b4a-4106-91db-b64bd2a33cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate houses with no above-ground bedrooms\n",
    "no_beds = housing[housing['bedroom_abvgr']==0]\n",
    "# Look at the exposures of their basements\n",
    "no_beds['basemt_exposure'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354bd5e0-8c08-492e-ae19-95a99199bb36",
   "metadata": {},
   "source": [
    "All of these houses had at least average exposure, and most of them had \"good\" exposure, meaning it is entirely possible that their kitchens and bedrooms, despite technically being in the basement, had relatively normal windows, visibility, and access to the outdoors, and did not *feel* subterranean.  (And besides, Ames is famously [cyclone country](https://cyclones.com/).)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b642bff-42a6-4f23-9c45-817ebb0c3203",
   "metadata": {},
   "source": [
    "With that resolved, I turned my attention to the bathrooms.  It is perfectly normal for houses to have no half bathrooms, so these 0s were of no concern.  It is not very normal for houses to have no above-ground bathrooms, but much like the kitchens and bedrooms, it is plausible that they were in the basement.  However, unlike the kitchens and bedrooms, the dataset included a column for basement bathrooms.  Therefore, I checked if any houses had 0s in both their above- and below-ground bathroom columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e88c4-5d4b-48f3-9d71-d8b591cc11c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask\n",
    "no_full_baths = (housing['basemt_full_bath']==0)&(housing['full_bath']==0)\n",
    "# View the rows\n",
    "housing[no_full_baths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5122cc2-2e47-4ff1-ac79-48ec6d28c498",
   "metadata": {},
   "source": [
    "The contents surprised me.  It referred to single a townhouse built in 2006, meaning it must surely have had a full bathroom somewhere.  Very old, very rural, or otherwise very unusual houses [may sometimes](https://shunshelter.com/article/can-you-sell-a-house-without-a-bathroom) be allowed to sell without a full bathroom, but a normal construction in the 21st century would surely not.  However, depsite this egregious omission, the house listed two half bathrooms each in the basement and on the main floor.  As likely as it seems that there was some kind of error here, it would have been nigh impossible to pinpoint where and what it was.  Changing one of the 0s to represent a full bathroom, despite surely being correct, would have altered this house's representation in the model to be a 1400 square foot house with *5 bathrooms* that sold for nearly \\$200k.  Although this row undoubtedly contains some inaccuracies, I judged that attempting to correct it would likely only introduce more error.\n",
    "\n",
    "As weird and unlikely as they were, the 0s for kitchens, bedrooms, and bathrooms were allowed to stay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eea54b-7905-4b8b-b487-36085ce623f2",
   "metadata": {},
   "source": [
    "After all of that, at long last, all NAs were resolved.  Many of these values did not represent a problem at all, but rather were just an inconvenient way of representing the lack of something.  A handful did require a judgment call from me, but not in quantities or extents that raise too much alarm in my mind for the validity of the eventual model.  Only the column *lot_frontage* presented a true dilemma.  Far too many of these values were missing to comfortably drop the rows, nor was it appealing to drop this feature, that well may influence how much buyers are willing to pay for the property.  I decided to impute the mode for these NAs, but I will have to proceed cautiously about using this feature in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522a428-eb1a-4704-8e4d-52c5d0b78152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that they're all gone\n",
    "housing.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e0c923-3a38-4fe8-9b27-c9af3deb3b38",
   "metadata": {},
   "source": [
    "The reproducible, future-facing code to clean new data, based on what I learned and did here, can be found in the main report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
